{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/dmlc/web-data/raw/master/tvm/tutorial/tvm_support_list.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/04/nnvm-1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNVM – Computation graph intermediate representation (IR) stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. NNVM is to represent workloads from different frameworks into standardized computation graphs and then translate these high-level graphs into execution graphs\n",
    "2. The computation graph, which is presented in a framework-agnostic format, is inspired from the layer definition in Keras and tensor operators from numpy.\n",
    "3. NNVM also ships with routines, called Pass by following the LLVM convention, to manipulate these graphs. These routines either add new attributes into the graph to execute them or modify graphs to improve efficiency.\n",
    "4. NNVM compiler, which compiles a high-level computation graph into optimized machine codes\n",
    "5. NNVM provides a specification of the computation graph and operator with graph optimization routines, and operators are implemented and optimized for target hardware by using TVM\n",
    "6. This compiler can match and even outperform state-of-the-art performance on two radically different hardware: ARM CPU and Nvidia GPUs.\n",
    "7. NNVM is a runtime agnostic compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NNVM provides\n",
    "\n",
    "1. Interface of graph definition\n",
    "2. Optimizer\n",
    "3. Runtime of kernel functions on various hardwares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVM – Tensor IR stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This operators used in computation graphs and optimizes them for target backend hardware\n",
    "2. Unlike NNVM, it provides a hardware-independent, domain-specific language to simplify the operator implementation in the tensor index level.\n",
    "3. TVM also offers scheduling primitives, such as multi-threading, tiling, and caching, to optimize the computation to fully utilize the hardware resources.\n",
    "4. These schedules are hardware-dependent and can either be hand-coded or it is possible to search optimized schema automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/07/nnvm-2-2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do one sample program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 6 7 8], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.Variable([1, 2, 3, 4])\n",
    "b = tf.Variable([4, 4, 4, 4])\n",
    "c = tf.add(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNVM Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create graph using ```nnvm``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(%x, %y) {\n",
      "  %2 = elemwise_add(%x, %y)\n",
      "  ret %2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import nnvm\n",
    "import nnvm.symbol as sym\n",
    "x = sym.Variable(\"x\")\n",
    "y = sym.Variable(\"y\")\n",
    "z = sym.elemwise_add(x, y)\n",
    "compute_graph = nnvm.graph.create(z)\n",
    "print(compute_graph.ir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile graph using ```nnvm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (4,)\n",
    "deploy_graph, lib, params = nnvm.compiler.build(compute_graph, target=\"llvm\", shape={\"x\": shape}, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the graph in target CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.contrib import graph_runtime, util\n",
    "module = graph_runtime.create(deploy_graph, lib, tvm.cpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_np = np.array([1, 2, 3, 4]).astype(\"float32\")\n",
    "y_np = np.array([4, 4, 4, 4]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set input to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.contrib.graph_runtime.GraphModule at 0x10bce93d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.set_input(x=x_np, y=y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = module.get_output(0, out=tvm.nd.empty(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(out.asnumpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
